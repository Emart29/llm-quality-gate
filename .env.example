# ============================================================================
# LLM Quality Gate - Environment Configuration
# ============================================================================
# 
# This file contains all the environment variables needed to run LLMQ.
# Copy this file to `.env` and fill in your actual API keys.
#
# Usage:
#   cp .env.example .env
#   # Edit .env with your actual API keys
#   python -m integrations.cli.main eval --provider groq
#
# ============================================================================

# ── Free/Open-source LLM Providers ─────────────────────────────────────────
# These providers offer free tiers or open-source models

# Groq - Fast inference for open models (Llama, Mixtral, etc.)
# Get your key at: https://console.groq.com/keys
GROQ_API_KEY=

# HuggingFace - Access to thousands of open models
# Get your key at: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=

# OpenRouter - Access to multiple models through one API
# Get your key at: https://openrouter.ai/keys
OPENROUTER_API_KEY=

# ── Proprietary LLM Providers ──────────────────────────────────────────────
# These providers require paid API access

# OpenAI - GPT models (GPT-3.5, GPT-4, etc.)
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Anthropic - Claude models (Claude 3 Haiku, Sonnet, Opus)
# Get your key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# Google - Gemini models (Gemini 1.5 Flash, Pro)
# Get your key at: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=

# ── Local/Self-hosted Providers ────────────────────────────────────────────
# These providers run locally or on your infrastructure

# LocalAI - Self-hosted OpenAI-compatible API
# Only needed if you're using authentication with LocalAI
LOCALAI_API_KEY=

# ── Optional Configuration Overrides ───────────────────────────────────────
# These override defaults in config.yaml

# Default provider to use when none specified
# LLM_DEFAULT_PROVIDER=groq

# Default temperature for all providers (0.0 = deterministic, 1.0 = creative)
# LLM_TEMPERATURE=0.0

# Default maximum tokens for responses
# LLM_MAX_TOKENS=1000

# Default timeout for API requests (seconds)
# LLM_TIMEOUT=30

# ── Database Configuration ──────────────────────────────────────────────────
# Override default database location

# Path to DuckDB database file
# LLMQG_DB_PATH=llmqg.duckdb

# ── CI/CD Integration ───────────────────────────────────────────────────────
# These are typically set in your CI/CD environment

# Git commit hash (auto-detected in CI)
# COMMIT_HASH=

# Git branch name (auto-detected in CI)
# BRANCH_NAME=

# CI trigger type (push, pull_request, manual)
# CI_TRIGGER=

# ── Notification Configuration ──────────────────────────────────────────────
# For alerts and notifications

# Slack webhook URL for notifications
# SLACK_WEBHOOK_URL=

# Email settings for notifications
# SMTP_HOST=
# SMTP_PORT=587
# SMTP_USERNAME=
# SMTP_PASSWORD=
# NOTIFICATION_EMAIL_FROM=
# NOTIFICATION_EMAIL_TO=

# ============================================================================
# Provider-specific Notes:
# ============================================================================
#
# Groq:
#   - Free tier: 30 requests/minute, 6000 requests/day
#   - Best for: Fast inference, development, testing
#   - Models: Llama 3, Mixtral, Gemma
#
# OpenAI:
#   - Pay-per-use pricing
#   - Best for: Production workloads, high-quality outputs
#   - Models: GPT-3.5-turbo, GPT-4, GPT-4-turbo
#
# Anthropic:
#   - Pay-per-use pricing
#   - Best for: Safety-focused applications, analysis
#   - Models: Claude 3 Haiku (fast), Sonnet (balanced), Opus (powerful)
#
# Google Gemini:
#   - Free tier available with rate limits
#   - Best for: Multimodal tasks, long context
#   - Models: Gemini 1.5 Flash (fast), Gemini 1.5 Pro (powerful)
#
# HuggingFace:
#   - Free tier for Inference API
#   - Best for: Open models, experimentation
#   - Models: Thousands of community models
#
# OpenRouter:
#   - Pay-per-use, access to multiple providers
#   - Best for: Model comparison, fallback scenarios
#   - Models: GPT, Claude, Llama, and many others
#
# Local Providers (Ollama, LocalAI):
#   - No API keys needed
#   - Best for: Privacy, offline usage, cost control
#   - Requires local setup and model downloads
#
# ============================================================================